import tensorflow as tf
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from cleverhans.tf2.attacks import fast_gradient_method

# Data loading and preparation
names = ['duration', 'protocol', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 
         'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 
         'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 
         'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 
         'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 
         'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 
         'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 
         'dst_host_srv_rerror_rate', 'attack_type', 'other']

df = pd.read_csv('KDDTrain+.txt', names=names, header=None)
dft = pd.read_csv('KDDTest+.txt', names=names, header=None)

# Combine the data
full = pd.concat([df, dft])
assert full.shape[0] == df.shape[0] + dft.shape[0]
print("Initial test and training data shapes:", df.shape, dft.shape)

# Check if the 'label' column exists in the full DataFrame
if 'label' not in full.columns:
    # Rename or create the label column if necessary, for example, if 'attack_type' is used
    full['label'] = full['attack_type']

# Reclassify labels into broader categories
dos_labels = ['neptune', 'back', 'land', 'pod', 'smurf', 'teardrop', 'mailbomb', 'processtable', 'udpstorm', 'apache2', 'worm']
u2r_labels = ['buffer_overflow', 'loadmodule', 'perl', 'rootkit', 'sqlattack', 'xterm', 'ps']
r2l_labels = ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster', 'xlock', 'xsnoop', 
              'snmpgetattack', 'httptunnel', 'snmpguess', 'sendmail', 'named']
probe_labels = ['satan', 'ipsweep', 'nmap', 'portsweep', 'saint', 'mscan']

# Reclassify labels into broader categories
full.loc[full['attack_type'].isin(dos_labels), 'label'] = 'dos'
full.loc[full['attack_type'].isin(u2r_labels), 'label'] = 'u2r'
full.loc[full['attack_type'].isin(r2l_labels), 'label'] = 'r2l'
full.loc[full['attack_type'].isin(probe_labels), 'label'] = 'probe'

# Drop unnecessary columns
full = full.drop(['other', 'attack_type'], axis=1)
print("Unique labels", full['label'].unique())

# Convert categorical columns to dummy variables
full2 = pd.get_dummies(full, drop_first=False)
features = list(full2.columns[:-5])

y_train = np.array(full2[0:df.shape[0]][['label_normal', 'label_dos', 'label_probe', 'label_r2l', 'label_u2r']])
X_train = full2[0:df.shape[0]][features]
y_test = np.array(full2[df.shape[0]:][['label_normal', 'label_dos', 'label_probe', 'label_r2l', 'label_u2r']])
X_test = full2[df.shape[0]:][features]

# Normalize the data
scaler = MinMaxScaler().fit(X_train)
X_train_scaled = np.array(scaler.transform(X_train))
X_test_scaled = np.array(scaler.transform(X_test))

labels = full['label'].unique()
le = LabelEncoder()
le.fit(labels)

y_full = le.transform(full['label'])
y_train_l = y_full[0:df.shape[0]]
y_test_l = y_full[df.shape[0]:]

print("Training dataset shape", X_train_scaled.shape, y_train.shape)
print("Test dataset shape", X_test_scaled.shape, y_test.shape)
print("Label encoder y shape", y_train_l.shape, y_test_l.shape)

# Define the MLP model
def mlp_model():
    model = Sequential()
    model.add(Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)))
    model.add(Dropout(0.4))
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.4))
    model.add(Dense(5, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.summary()
    return model

# Train the MLP model
model = mlp_model()
model.fit(X_train_scaled, y_train, batch_size=128, epochs=10, validation_data=(X_test_scaled, y_test))

# Evaluate the model
def evaluate_model():
    loss, accuracy = model.evaluate(X_test_scaled, y_test, batch_size=128)
    print(f'Test accuracy on legitimate test examples: {accuracy}')

evaluate_model()

# Adversarial attacks (using CleverHans)
#def create_adversarial_samples(model, x_test):
    # Make sure to use model for prediction and feeding input properly
 #   adv_x = fast_gradient_method(model, x_test, epsilon=0.3, norm=np.inf)
  #  return adv_x

def create_adversarial_samples(model, x_test):
    # Get the logits (raw predictions) from the model
    logits = model(x_test)
    # Use fast_gradient_method to generate adversarial examples
    adv_x = fast_gradient_method(logits, x_test, epsilon=0.3, norm=np.inf)
    return adv_x

# Example of using adversarial attacks
adv_x_test = create_adversarial_samples(model, X_test_scaled)

# Optionally evaluate on adversarial samples
adv_y_pred = model.predict(adv_x_test)
adv_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(adv_y_pred, axis=1))
print(f'Accuracy on adversarial samples: {adv_accuracy}')
